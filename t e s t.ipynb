{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153740bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def get_background(file_path):\n",
    "    cap = cv2.VideoCapture(file_path)\n",
    "    frames = []\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Handle frames with different dimensions, if necessary\n",
    "        # frame = cv2.resize(frame, (desired_width, desired_height))\n",
    "\n",
    "        frames.append(frame)\n",
    "\n",
    "    cap.release()  # Release the video capture object\n",
    "    if frames:\n",
    "        median_frame = np.median(frames, axis=0).astype(np.uint8)\n",
    "        return median_frame\n",
    "    else:\n",
    "        # Handle the case when no frames are read\n",
    "        print(\"Error: No frames were read from the video.\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "background = get_background(\"HethenHisPelivideo.mp4\")\n",
    "\n",
    "if background is not None:\n",
    "    print(\"Background data type:\", background.dtype)\n",
    "    background_gray = cv2.cvtColor(background, cv2.COLOR_BGR2GRAY)\n",
    "    print(\"Background data type after conversion:\", background_gray.dtype)\n",
    "else:\n",
    "    print(\"Error: No valid background frame.\")\n",
    "\n",
    "\n",
    "\n",
    "def ORB_detector(new_image, image_template):\n",
    "    orb = cv2.ORB_create(1000, 1.2)  # ORB detector of 1000 keypoints, scaling pyramid factor=1.2\n",
    "    (kp1, des1) = orb.detectAndCompute(new_image, None)  # Detect keypoints on the new image\n",
    "    (kp2, des2) = orb.detectAndCompute(image_template, None)  # Detect keypoints of the template image\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)  # Matcher\n",
    "    matches = bf.match(des1, des2)  # Extract matches\n",
    "    matches = sorted(matches, key=lambda val: val.distance)  # Sort matches\n",
    "    img2 = cv2.drawKeypoints(image_template, kp2, None, color=(0,255,0), flags=0)\n",
    "    img1 = cv2.drawKeypoints(new_image, kp2, None, color=(0,255,0), flags=0)\n",
    "    plt.imshow(img2)\n",
    "    plt.show()\n",
    "    return len(matches)\n",
    "\n",
    "# Load video file and template image\n",
    "\n",
    "consecutive_frames = 4\n",
    "\n",
    "background = get_background(\"He&HisPelivideo.mp4\")\n",
    "print(\"Background data type:\", background.dtype)\n",
    "background_gray = cv2.cvtColor(background, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "frame_count = 0\n",
    "frame_diff_list = []\n",
    "\n",
    "while True:\n",
    "    cap = cv2.VideoCapture(\"He&HisPelivideo.mp4\")\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    frame_count += 1\n",
    "    orig_frame = frame.copy()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY).astype(np.uint8)\n",
    "    print(\"Background shape:\", background.shape)\n",
    "    print(\"Gray shape:\", gray.shape)\n",
    "\n",
    "    frame_diff = cv2.absdiff(gray, background_gray)\n",
    "    ret, thres = cv2.threshold(frame_diff, 50, 255, cv2.THRESH_BINARY)\n",
    "    dilate_frame = cv2.dilate(thres, None, iterations=2)\n",
    "    frame_diff_list.append(dilate_frame)\n",
    "    if len(frame_diff_list) == consecutive_frames:\n",
    "        sum_frames = sum(frame_diff_list)\n",
    "        contours, hierarchy = cv2.findContours(sum_frames, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        for contour in contours:\n",
    "            if cv2.contourArea(contour) < 500:\n",
    "                continue\n",
    "            (x, y, w, h) = cv2.boundingRect(contour)\n",
    "            cv2.rectangle(orig_frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "        # Get height and width of webcam frame\n",
    "        height, width = frame.shape[:2]\n",
    "\n",
    "        # Define ROI Box Dimensions (Note some of these things should be outside the loop)\n",
    "        top_left_x = int(width / 3)\n",
    "        top_left_y = int((height / 2) + (height / 4))\n",
    "        bottom_right_x = int((width / 3) * 2)\n",
    "        bottom_right_y = int((height / 2) - (height / 4))\n",
    "\n",
    "        # Draw rectangular window for our region of interest\n",
    "        # cv2.rectangle(frame, (top_left_x,top_left_y), (bottom_right_x,bottom_right_y), 255, 3)\n",
    "\n",
    "        # Crop window of observation we defined above\n",
    "        cropped = frame[bottom_right_y:top_left_y , top_left_x:bottom_right_x]\n",
    "\n",
    "        # Flip frame orientation horizontally\n",
    "        frame = cv2.flip(frame,1)\n",
    "\n",
    "        # Get number of ORB matches \n",
    "        matches = ORB_detector(cropped, image_template)\n",
    "\n",
    "        # Display status string showing the current no. of matches \n",
    "        output_string = \"Matches = \" + str(matches)\n",
    "        cv2.putText(frame, output_string, (50,450), cv2.FONT_HERSHEY_COMPLEX, 2, (250,0,150), 2)\n",
    "\n",
    "        # Our threshold to indicate object deteciton\n",
    "        # For new images or lightening conditions you may need to experiment a bit \n",
    "        # Note: The ORB detector to get the top 1000 matches, 350 is essentially a min 35% match\n",
    "        threshold = 336\n",
    "\n",
    "        # If matches exceed our threshold then object has been detected\n",
    "        if matches > threshold:\n",
    "            cv2.rectangle(frame, (top_left_x,top_left_y), (bottom_right_x,bottom_right_y), (0,255,0), 3)\n",
    "            cv2.putText(frame,'Object Found',(50,50), cv2.FONT_HERSHEY_COMPLEX, 2 ,(0,255,0), 2)\n",
    "            # Display the frame with the detected object\n",
    "        cv2.imshow('Object Detector using ORB', frame)\n",
    "\n",
    "        cv2.imshow('Detected Objects', orig_frame)\n",
    "        if cv2.waitKey(100) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5b5bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
